# **PCL-Reasoner-V1.5 æ•°å­¦æ¨ç†æ¨¡å‹**

## æ¨¡å‹æ¦‚è§ˆ

PCL-Reasoner-V1.5 æ˜¯ä¸€ä¸ªä¸“ä¸ºæ•°å­¦æ¨ç†è®¾è®¡çš„ 32B å‚æ•°å¤§è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åŸºäº Qwen2.5-32B-Base æ„å»ºï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰ä¸å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬æ–¹æ³•çš„ä¸€é¡¹å…³é”®åˆ›æ–°åœ¨äºé‡‡ç”¨äº†ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline RLï¼‰ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚
åœ¨å…¬å¼€æ•°æ®é›†ä¸Šï¼ŒPCL-Reasoner-V1.5 åœ¨ 32B è§„æ¨¡æ¨¡å‹ä¸­è¡¨ç°å“è¶Šï¼š

- åœ¨ AIME 2024 åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ° 91.3% çš„å¹³å‡å‡†ç¡®ç‡
- åœ¨ AIME 2025 åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ° 91.0% çš„å¹³å‡å‡†ç¡®ç‡

æ‰€æœ‰å®éªŒå‡åœ¨åä¸ºæ˜‡è…¾ï¼ˆAscendï¼‰NPU ä¸Šå®Œæˆï¼Œä»…ä½¿ç”¨å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ã€‚

ä¸ºä¿ƒè¿›æŠ€æœ¯å…±äº«ä¸åº”ç”¨ï¼Œæˆ‘ä»¬å·²å®Œæ•´å¼€æºäº†PCL-Reasoner-V1.5çš„æ¨¡å‹æƒé‡ã€æ•°æ®å¤„ç†åŠè®­ç»ƒä»£ç ã€‚è¯¥æ¨¡å‹ä¸ä»…æ˜¯å½“ä¸‹é¢†å…ˆçš„32Bæ•°å­¦æ¨ç†æ¨¡å‹ä¹‹ä¸€ï¼Œæ›´ä¸ºå¼€å‘è€…æä¾›äº†å®è´µçš„ä¸“ä¸šé¢†åŸŸç¦»çº¿å¼ºåŒ–å­¦ä¹ å®è·µç»éªŒä¸åè®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚ç”¨æˆ·å¯å‚ç…§ä»¥ä¸‹æ•™ç¨‹è½»æ¾éƒ¨ç½²ä½“éªŒï¼Œæ·±å…¥æ¢ç´¢åè®­ç»ƒçš„å®è·µæ–¹æ³•ä¸å¥¥ç§˜ï¼


## å¼€å‘æŒ‡å¯¼

### 1. è®­ç»ƒä»£ç 

PCL-Reasoner-V1.5åŸºäºPCL-Reasoner-V1è¿›è¡Œå¾®è°ƒåè®­ç»ƒï¼Œè®­ç»ƒæµç¨‹åŸºäºMindSpeed-LLMæ¡†æ¶å®ç°ï¼Œæˆ‘ä»¬ä¸»è¦å¢åŠ äº†ä¸€ä¸ª`opg_trainer.py`ï¼Œå’Œå¯¹æ•°æ®é›†çš„å¤„ç†ä¸­ï¼Œæ·»åŠ äº†`reward`å…³é”®å­—ã€‚ä¸ºäº†æ–¹ä¾¿å¼€æºç¤¾åŒºå¤ç°ï¼Œæˆ‘ä»¬å°†æ•´ä¸ªè®­ç»ƒä»£ç æ‰“åŒ…æ”¾åˆ°å½“å‰ç›®å½•`MindSpeed-LLM`ä¸‹é¢ã€‚

### 2.ç¯å¢ƒåŠæ•°æ®å‡†å¤‡

#### 2.1 å®‰è£…ç¯å¢ƒï¼š

| è½¯ä»¶      | ç‰ˆæœ¬       |
| --------- | ---------- |
| å›ºä»¶&é©±åŠ¨ | 24.1.rc3.5 |
| CANN      | 8.3.RC1    |
| Python    | 3.10       |
| MindSpeed | commit: 887c2d868 |


#### 2.2 æ•°æ®å¤„ç†

##### 2.2.1 æ•°æ®é›†ä¸‹è½½

åœ¨å‰æœŸå·¥ä½œä¸­ï¼Œæˆ‘ä»¬å·²ç»å°†PCL-Reasoner-V1çš„æ•°å­¦æ¨ç†èƒ½åŠ›æå‡åˆ°äº†å¾ˆé«˜çš„æ°´å¹³ã€‚ä¸ºäº†è¿›ä¸€æ­¥ä¼˜åŒ–æ¨¡å‹æ€§èƒ½ï¼Œæˆ‘ä»¬è€ƒè™‘ä»NVIDIAå…¬å¼€çš„Nemotron-Post-Training-Dataset-v1æ•°æ®é›†ä¸­ç­›é€‰å…·æœ‰ä¸€å®šéš¾åº¦çš„é¢˜ç›®ï¼Œç”¨äºåç»­çš„å¼ºåŒ–è®­ç»ƒã€‚

| æ•°æ®é›†åç§°                    | æ•°æ®é›†é“¾æ¥                                                                                                                     |
| ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| nvidia/Nemotron-Post-Training-Dataset-v1 | [https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v1](https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v1) |

##### 2.2.2 æ•°æ®é¢„å¤„ç†

æ•°æ®é›†ä¸‹è½½åä¸ºparquetæ ¼å¼ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ•°æ®é›†è½¬æ¢ä¸ºjsonlæ ¼å¼ï¼Œæ–¹ä¾¿åç»­å¤„ç†ã€‚

```bash
# dir_path_to_parquet_files=Nemotron-Post-Training-Dataset-v1/data
# output_dir_path=Nemotron-Post-Training-Dataset-v1/orig2jsonl
cd data_preprocess
python convert_parquet2jsonl.py $dir_path_to_parquet_files $output_dir_path  --workers 128
# å°†æ•°æ®é›†åˆå¹¶ä¸ºä¸€ä¸ªjsonlæ–‡ä»¶
cat $output_dir_path/*jsonl > Nemotron-Post-Training-Dataset-v1/all_samples.jsonl
```

ç»è¿‡ç»Ÿè®¡åˆ†æï¼Œæˆ‘ä»¬å‘ç°åœ¨æ•°æ®é›†Nemotron-Post-Training-Dataset-v1ä¸­ï¼Œæ¯é“é¢˜è¢«å¤šæ¬¡é‡‡ç”¨ï¼Œä¸”ä»…ä¿ç•™äº†æ­£ç¡®çš„COTï¼ˆChain of Thoughtï¼‰æ ·æœ¬ã€‚åŸºäºæ­¤ç°è±¡ï¼Œæˆ‘ä»¬å¯ä»¥è®¡ç®—æ¯é“é¢˜çš„å‡†ç¡®ç‡å’ŒCOTé•¿åº¦ã€‚æ•´ä¸ªæ•°æ®é¢„å¤„ç†è¿‡ç¨‹åˆ†ä¸ºä»¥ä¸‹ä¸‰ä¸ªæ­¥éª¤ï¼š

1. **åˆ†ç¦»å®Œå…¨æ­£ç¡®ä¸éƒ¨åˆ†æ­£ç¡®æ ·æœ¬**ï¼šæˆ‘ä»¬ç»Ÿè®¡äº†åŸå§‹æ•°æ®é›†ä¸­ç›¸åŒé¢˜ç›®çš„COTæ•°é‡ï¼Œå‘ç°å¤§éƒ¨åˆ†é¢˜ç›®å¯¹åº”1-16æ¡COTï¼Œæå°‘æ•°é¢˜ç›®å¯¹åº”17-32æ¡COTã€‚æ®æ­¤åˆ¤æ–­ï¼ŒåŸå§‹æ•°æ®é›†å¯¹æ¯é“é¢˜è¿›è¡Œäº†16æ¬¡æ¨ç†ï¼Œç„¶åä»…ä¿ç•™äº†æ­£ç¡®çš„COTæ ·æœ¬ã€‚å…¶ä¸­17-32æ¡çš„æ ·æœ¬å¯è§†ä¸ºå°‘é‡é‡å¤é¢˜ç›®ã€‚å› æ­¤ï¼Œç¬¬ä¸€æ­¥æ˜¯è¿‡æ»¤æ‰COTæ•°é‡ä¸º16å’Œ32çš„æ ·æœ¬ï¼ˆå³å®Œå…¨æ­£ç¡®çš„æ ·æœ¬ï¼‰ï¼Œä¿ç•™éƒ¨åˆ†æ­£ç¡®çš„æ ·æœ¬ï¼š
    ```bash
    # cd data_preprocess 
    python split_all_right_and_partial_right.py all_samples.jsonl --complete_output all_right_samples.jsonl --incomplete_output partial_right_samples.jsonl --processes 128 
    ```
   åŸå§‹æ•°æ®é›†åŒ…å«2,044,407æ¡COTæ•°æ®ï¼Œç»è¿‡å¤„ç†åï¼Œæˆ‘ä»¬å¾—åˆ°1,189,392æ¡å®Œå…¨æ­£ç¡®çš„COTæ•°æ®ï¼ˆå·²è¿‡æ»¤æ‰å…¨å¯¹é¢˜ç›®ï¼‰å’Œ855,015æ¡éƒ¨åˆ†æ­£ç¡®çš„COTæ•°æ®ã€‚

2. **ç­›é€‰é•¿COTæ ·æœ¬**ï¼šä»855,015æ¡éƒ¨åˆ†æ­£ç¡®çš„COTæ•°æ®ä¸­ç­›é€‰å‡ºå¹³å‡COTé•¿åº¦å¤§äº32Kçš„æ ·æœ¬ï¼š
    ```bash
    # cd data_preprocess 
    python static_and_filter_cot.py partial_right_samples.jsonl partial_right_samples_cot_filter.jsonl path_to_tokenizer --processes 128
    ```
    å¤„ç†åï¼Œæˆ‘ä»¬å¾—åˆ°çº¦34Kæ¡é¢˜ç›®ï¼Œä¸”å¹³å‡COTé•¿åº¦å‡è¶…è¿‡32Kã€‚

3. **æå–å”¯ä¸€é¢˜ç›®**ï¼šä»34Kæ¡COTæ•°æ®ä¸­æå–é¦–æ¬¡å‡ºç°çš„å”¯ä¸€é¢˜ç›®ï¼š
   
   ```bash
   # cd data_preprocess 
   python extract_first_problem.py partial_right_samples_cot_filter.jsonl partial_right_problem.jsonl
   ```
   æœ€ç»ˆå¤„ç†åï¼Œæˆ‘ä»¬å¾—åˆ°çº¦6Kæ¡å”¯ä¸€çš„é¢˜ç›®ã€‚


##### 2.2.3 æ¨¡å‹é‡‡æ ·

è·å¾—6Kæ•°æ®é›†åï¼Œæˆ‘ä»¬ä½¿ç”¨`PCL-Reasoner-V1`æ¨¡å‹è¿›è¡Œé‡‡æ ·ï¼Œæ¯é“é¢˜é‡‡æ ·8æ¬¡ï¼Œç”Ÿæˆæ¨ç†ç»“æœã€‚é‡‡æ ·é…ç½®è·Ÿåé¢çš„è¯„ä¼°ä¸€è‡´ï¼š

| é‡‡æ ·è¶…å‚       | å–å€¼                                       |
| -------------- | ------------------------------------------ |
| temperature    | 0.6                                        |
| top_k         | 40                                         |
| top_p         | 0.95                                       |
| max_model_len    | 131072                                     |
| system_prompt_type | amthinking |

ç»è¿‡é‡‡æ ·ï¼Œæˆ‘ä»¬å¾—åˆ°äº†48Kçš„COTæ•°æ®ã€‚

##### 2.2.4 é‡‡æ ·COTæ­£ç¡®æ€§è¯„ä¼°

åŸºäºä»¥å¾€è®­ç»ƒç»éªŒï¼Œæˆ‘ä»¬å‘ç°ä¼ ç»Ÿçš„math_verifyæ–¹æ³•æ— æ³•æœ‰æ•ˆè¯„ä¼°COTå›ç­”çš„æ­£ç¡®æ€§ã€‚å¯¹äºå¤æ‚çš„æ•°å­¦é¢˜ï¼Œä½¿ç”¨è§„åˆ™åŒ¹é…çš„æ–¹å¼å®¹æ˜“äº§ç”Ÿè¾ƒå¤§è¯¯åˆ¤ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨Qwen3-32Bæ¨¡å‹å¯¹COTå›ç­”çš„æ­£ç¡®æ€§è¿›è¡Œè¯„ä¼°ï¼Œå…·ä½“æ€è·¯å¦‚ä¸‹ï¼š

1. ä¸º`Qwen3-32B`æ¨¡å‹è®¾è®¡ä¸“é—¨çš„promptï¼Œç”¨äºåˆ¤æ–­COTä¸­åŒ…å«çš„æœ€ç»ˆç­”æ¡ˆæ˜¯å¦ä¸é¢˜ç›®æä¾›çš„`ground truth`ä¸€è‡´ï¼›
2. éƒ¨ç½²`Qwen3-32B`æ¨¡å‹å¯¹48Ké¢˜ç›®è¿›è¡Œæ¨ç†è¯„ä¼°ï¼›
3. æ ¹æ®`Qwen3-32B`æ¨¡å‹å¯¹COTæœ€å300ä¸ªtokenä¸­åŒ…å«çš„ç­”æ¡ˆä¸é¢˜ç›®æä¾›çš„`ground truth`è¿›è¡ŒåŒ¹é…ï¼Œä»è€Œåˆ¤æ–­è¯¥æ¡COTæ˜¯å¦æ­£ç¡®ã€‚

è¯„ä¼°promptæ¨¡æ¿å¦‚ä¸‹ï¼š

```bash
As a math scoring expert, given a standard answer, and a candidate answer, you need to compare whether the standard answer and the candidate answer are consistent. If they are consistent, return 1; if not, return 0. Remember the returned value should always be put in the \\boxed{}.\nHere are a few points to note:\n1. For the candidate answer, only consider the content inside \\boxed{}, ignoring any other text or error. If no \\boxed{} found, return 0 directly.\n2. If the standard answer and the candidate answer are different but mathematically equivalent, return 1.\n3. For answers involving decimals, if most digits are the same and only the last one or two digits differ, you may considerably return 1.\n4. For all other cases where the standard answer and the candidate answer do not match, return 0.\nHere is a task example:\n<Standard Answer Begin>\n{Standard answer}\n<Standard Answer End>\n<Candidate Answer Begin>\n{Candidate answer}\n<Candidate Answer End>\nPlease put your return value (0 or 1) as required above in the \\boxed{} without any explanation or description.
```

æœ€ç»ˆï¼Œæˆ‘ä»¬è·å¾—äº†22,990æ¡æ­£æ ·æœ¬å’Œ25,522æ¡è´Ÿæ ·æœ¬ã€‚

#### 2.3 æ¨¡å‹æƒé‡å‡†å¤‡

ç”¨æˆ·å¯ä»¥ä»`HuggingFace`å®˜æ–¹ä¸‹è½½`PCL-Reasoner-V1`æƒé‡

| æ¨¡å‹åç§°          | æƒé‡é“¾æ¥                                                                           |
| ----------------- | ---------------------------------------------------------------------------------- |
| PCL-Reasoner-V1 | [https://huggingface.co/PCL-Reasoner/V1](https://huggingface.co/PCL-Reasoner/V1) |

### 3 è®­ç»ƒæµç¨‹

æˆ‘ä»¬çš„è®­ç»ƒåŸºäºMindspeed-LLMæ¡†æ¶æ¶ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š

#### 3.1 æ¨¡å‹æƒé‡è½¬æ¢

##### 3.1.1 ä¸‹è½½HuggingFaceæ¨¡å‹æƒé‡

ä¸‹è½½ HuggingFace ä¸Šçš„ PCL-Reasoner/V1 æ¨¡å‹æƒé‡åˆ°æœ¬åœ°ã€‚

```bash
# download  model
huggingface-cli download  PCL-Reasoner/V1  --local-dir ~/local/PCL-Reasoner/V1
```

##### 3.1.2 è½¬æ¢æ¨¡å‹æƒé‡æ ¼å¼

MindSpeed-LLMæ¡†æ¶åŸºäºMindSpeedï¼Œè¯»å–æƒé‡æ ¼å¼ä¸ºmcoreæ ¼å¼ï¼Œåœ¨è®­ç»ƒå‰ï¼Œéœ€è¦å°† Hugging Face æƒé‡è½¬æ¢æˆMcoreæ ¼å¼ã€‚è„šæœ¬å¯åŠ¨å‘½ä»¤å¯ä»¥ç”¨bashå¯åŠ¨ï¼Œå¯æ ¹æ®çœŸå®æƒ…å†µé…ç½®è„šæœ¬ï¼Œå¯åŠ¨å‘½ä»¤å’Œé…ç½®å‚æ•°å¦‚ä¸‹ï¼š
```bash
source /usr/local/Ascend/ascend-toolkit/set_env.sh

hf_model_path=/path/to/hf/model
# è®¾ç½®éœ€è¦çš„æƒé‡è½¬æ¢å‚æ•°
cd MindSpeed-LLM
python convert_ckpt.py \
       --use-mcore-models \
       --model-type GPT \
       --load-model-type hf \
       --save-model-type mg \
       --target-tensor-parallel-size 8 \
       --target-pipeline-parallel-size 4 \
       --add-qkv-bias \
       --load-dir $hf_model_path \
       --save-dir ${hf_model_path}/mcore_tp8_pp4/ \
       --tokenizer-model $hf_model_path/tokenizer.json \
       --model-type-hf llama2 \
       --params-dtype bf16 
```

###### å‚æ•°ä»‹ç»

- `use-mcore-models`ï¼šå¯ç”¨ MCore æ¨¡å‹ï¼›
- `model-type`ï¼šæŒ‡å®šæ¨¡å‹ç±»å‹ï¼Œå¦‚ GPT;
- `load-model-type`ï¼šæŒ‡å®šåŠ è½½æ¨¡å‹çš„ç±»å‹ï¼Œå¦‚ hfï¼ˆHugging Faceï¼‰;
- `save-model-type`ï¼šæŒ‡å®šä¿å­˜æ¨¡å‹çš„ç±»å‹ï¼Œå¦‚ mg;
- `target-tensor-parallel-size`ï¼šè®¾ç½®ç›®æ ‡å¼ é‡å¹¶è¡Œå¤§å°ï¼›
- `target-pipeline-parallel-size`ï¼šè®¾ç½®ç›®æ ‡æµæ°´çº¿å¹¶è¡Œå¤§å°ï¼›
- `add-qkv-bias`ï¼šæ˜¯å¦è¿›è¡Œ QKV åç½®ï¼›
- `load-dir`ï¼šåŠ è½½ Hugging Face æƒé‡çš„è·¯å¾„ï¼›
- `save-dir`ï¼šä¿å­˜è½¬æ¢åæƒé‡çš„è·¯å¾„ï¼›
- `tokenizer-model`ï¼šåˆ†è¯å™¨æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ï¼›
- `model-type-hf`ï¼šæŒ‡å®š Hugging Face æ¨¡å‹ç±»å‹ï¼Œå¦‚ llama2;
- `params-dtype`ï¼šæŒ‡å®šå‚æ•°çš„æ•°æ®ç±»å‹ï¼Œå¦‚ bf16ã€‚



#### 3.2 æ•°æ®é›†è½¬æ¢

ç»è¿‡æ¨ç†ï¼Œæˆ‘ä»¬å¾—åˆ°äº†48Kçš„COTæ•°æ®ï¼Œæ•°æ®æ ¼å¼ä¸ºjsonlæ ¼å¼ï¼ŒåŒ…å«é—®é¢˜ã€æ¨ç†ç»“æœå’Œæ¨ç†ç»“æœå¯¹åº”çš„COTã€‚éœ€è¦å°†å…¶è½¬æ¢ä¸ºMindSpeed-LLMçš„å¯è¯»æ ¼å¼ï¼š


```bash
# è¯·æŒ‰ç…§æ‚¨çš„çœŸå®ç¯å¢ƒä¿®æ”¹ set_env.sh è·¯å¾„
source /usr/local/Ascend/ascend-toolkit/set_env.sh

hf_model_path=/path/to/hf/model
python preprocess_data.py \
    --input /path/to/opg_train_remove_all_wrong_cot_lt_48k.jsonl \
    --tokenizer-type PretrainedFromHF \
    --tokenizer-not-use-fast \
    --tokenizer-name-or-path $hf_model_path \
    --output-prefix /path/to/mc_lt_48k/ \
    --workers 64 \
    --log-interval 1000 \
    --handler-name AlpacaStyleInstructionHandler \
    --prompt-type empty \
    --cache-dir /path/to/tmp/ \
    --map-keys '{"prompt":"prompt", "query":"", "response":"response", "reward":"reward"}'
```

#####

- `input`: è¾“å…¥jsonlæ–‡ä»¶è·¯å¾„
- `tokenizer-type`: è¾“å…¥çš„tokenizerç±»å‹
- `tokenizer-name-or-path`: è¾“å…¥çš„tokenizerè·¯å¾„
- `output-prefix`: è¾“å‡ºæ–‡ä»¶è·¯å¾„
- `workers`: æ•°æ®å¤„ç†çº¿ç¨‹æ•°
- `log-interval`: æ—¥å¿—è¾“å‡ºæ ·æœ¬æ•°é—´éš”
- `handler-name`: é€‰æ‹©çš„`data handler`åç§°
- `prompt-type`: è¾“å…¥çš„promptç±»å‹ï¼Œemptyè¡¨ç¤ºæ— promptï¼ˆè¯´æ˜åŸå§‹prompté‡Œé¢å·²ç»åŒ…å«äº†`chat template`)
- `cache-dir`: ç¼“å­˜ç›®å½•
- `map-keys`: è¾“å…¥çš„jsonlæ–‡ä»¶å­—æ®µæ˜ å°„


#### 3.3 è®­ç»ƒé…ç½®

æˆ‘ä»¬é‡‡ç”¨äº†ä¸€ç§å—å¯å‘çš„è®­ç»ƒç­–ç•¥ã€‚å…¨å±€æ‰¹å¤§å°ï¼ˆglobal batch sizeï¼‰è®¾ä¸º 128ï¼Œå­¦ä¹ ç‡ä»$6Ã—10^{âˆ’5}$æŒ‰ç…§ä½™å¼¦è¡°å‡è°ƒåº¦é™è‡³ $1Ã—10^{âˆ’7}$ï¼Œå¹¶è®¾ç½®äº† 0.05 çš„é¢„çƒ­æ¯”ä¾‹ï¼ˆwarm-up ratioï¼‰ã€‚AdamW ä¼˜åŒ–å™¨çš„åŠ¨é‡å‚æ•°é…ç½®ä¸º $\beta_1=0.9$ å’Œ $\beta_2=0.95$ã€‚è®­ç»ƒåœ¨ 16 å° Atlas 910C SuperPoD èŠ‚ç‚¹ï¼ˆæ¯å°åŒ…å« 8 ä¸ªèŠ¯ç‰‡ï¼‰ä¸Šè¿›è¡Œã€‚æ•´ä¸ªå¾®è°ƒè¿‡ç¨‹å…±è¿›è¡Œäº† 4 ä¸ª epochï¼Œè€—æ—¶çº¦ 116 å°æ—¶ã€‚ç›¸åº”çš„è®­ç»ƒæŸå¤±æ›²çº¿å¦‚å›¾ \ref{fig:loss} æ‰€ç¤ºã€‚

ä¸ºäº†æœ€å¤§åŒ–è®¡ç®—æ•ˆç‡ï¼Œæˆ‘ä»¬åœ¨ç›‘ç£å¾®è°ƒé˜¶æ®µå¯ç”¨äº†æ•°æ®æ‰“åŒ…ï¼ˆdata packingï¼‰åŠŸèƒ½ã€‚è¯¥åŠŸèƒ½å…è®¸å°†æ¯ä¸ªæ‰¹æ¬¡ä¸­é•¿åº¦å„å¼‚çš„æ ·æœ¬æ‹¼æ¥åˆå¹¶ï¼Œå¡«å…¥é¢„è®¾çš„åºåˆ—é•¿åº¦ï¼ˆ48K tokensï¼‰ä¸­ã€‚é€šè¿‡å°†å¤šä¸ªçŸ­åºåˆ—åˆå¹¶ä¸ºä¸€ä¸ªé•¿åºåˆ—ï¼Œæœ‰æ•ˆæ¶ˆé™¤äº†å› åºåˆ—å¡«å……ï¼ˆpaddingï¼‰å¸¦æ¥çš„å†—ä½™è®¡ç®—ï¼Œæ˜¾è‘—åŠ å¿«äº†è®­ç»ƒé€Ÿåº¦ã€‚

#### 3.4 å¯åŠ¨è®­ç»ƒ

è®­ç»ƒæµç¨‹åˆ†ä¸ºä¸‰æ­¥ï¼š

1. æ¿€æ´»ç¯å¢ƒï¼š`source /path/to/set_env.sh`
2. å¯åŠ¨è®­ç»ƒï¼š`cd MindSpeed-LLM; bash scripts/lauch_multi_nodes.sh node_list.txt`

### 4. è¯„æµ‹æµç¨‹ï¼š

æˆ‘ä»¬ä½¿ç”¨ [LLMEval](https://gitee.com/jianzhnie/LLMEval) å¯¹æ¨¡å‹è¿›è¡Œè¯„æµ‹ï¼Œ LLMEval æ˜¯ç”±æˆ‘ä»¬å›¢é˜Ÿå¼€å‘çš„ä¸»è¦é’ˆå¯¹å¤§æ¨¡å‹æ¨ç†è¿›è¡Œè¯„æµ‹çš„å·¥å…·ï¼Œæ”¯æŒ vllm å’Œ sglang ä¸¤ç§æ¨ç†åç«¯ï¼Œ æ”¯æŒå¤šç§è¯„æµ‹æ•°æ®é›†ï¼Œ å·²ç»åœ¨ Ascend ç¯å¢ƒå¤ç°äº†å¤šä¸ªå¼€æºæ¨ç†æ¨¡å‹çš„æ•ˆæœã€‚è¯¦æƒ…è¯·å‚è€ƒ [LLMEval ä½¿ç”¨æ•™ç¨‹](https://gitee.com/jianzhnie/LLMEval)ã€‚

#### 4.1 è¯„ä¼°ç¯å¢ƒé…ç½®

è¯·å‚è€ƒ [LLMEval ä½¿ç”¨æ•™ç¨‹](https://gitee.com/jianzhnie/LLMEval) ä¸­çš„ç¯å¢ƒé…ç½®ç« èŠ‚è¿›è¡Œç¯å¢ƒæ­å»ºã€‚


#### 4.2 å¼€å§‹è¯„æµ‹

##### æ­¥éª¤ 1ï¼šå¯åŠ¨ vLLM æœåŠ¡å™¨

```bash
source set_env.sh

model_path="/path/to/pcl_reasoner_v1"
model_name="PCL-Reasoner-v1"

num_gpus=8
max_model_len=131072  # âœ… æ”¯æŒ 128k ä¸Šä¸‹æ–‡
gpu_memory_utilization=0.9  # âœ… æé«˜å†…å­˜åˆ©ç”¨ç‡

python -m vllm.entrypoints.openai.api_server \
    --model $model_path \
    --trust-remote-code \
    --served-model-name $model_name \
    --tensor-parallel-size $num_gpus \
    --gpu-memory-utilization $gpu_memory_utilization \
    --max-model-len $max_model_len  \
    --enforce-eager \
    --port 8090
```

æ ¹æ®å¯ç”¨è®¾å¤‡è°ƒæ•´ `tensor_parallel_size` å‚æ•°ã€‚


##### æ­¥éª¤ 2ï¼šæäº¤æ¨ç†ä»»åŠ¡

å¯åŠ¨ vLLM æœåŠ¡åï¼Œè¿è¡Œæ¨ç†è„šæœ¬ç”Ÿæˆå“åº”, å¹¶å°†ç»“æœä¿å­˜åˆ°æŒ‡å®šçš„è¾“å‡ºæ–‡ä»¶ä¸­ã€‚

```bash
source set_env.sh

set -euo pipefail

# --- Configuration ---
output_dir="./output/PCL-Reasoner-v1"
model_name="PCL-Reasoner-v1"

base_url="http://127.0.0.1:8090/v1"
n_samples=64  # Default sample size for aime24 and aime25

# Create output directory if it doesn't exist
mkdir -p "${output_dir}"

# --- Run Inference Tasks ---
# aime25 (repeated sample 64 times)
python ./llmeval/vllm/online_server.py \
    --input_file "./data/aime25.jsonl" \
    --input_key "prompt" \
    --output_file "${output_dir}/aime25_bz${n_samples}.jsonl" \
    --base_url "${base_url}" \
    --model_name "${model_name}" \
    --n_samples "${n_samples}" \
    --temperature 0.6  \
    --system_prompt_type amthinking \
    --max_workers 64

# aime24 (repeated sample 64 times)
python ./llmeval/vllm/online_server.py \
    --input_file "./data/aime24.jsonl" \
    --input_key "prompt" \
    --output_file "${output_dir}/aime24_bz${n_samples}.jsonl" \
    --base_url "${base_url}" \
    --model_name "${model_name}" \
    --n_samples "${n_samples}" \
    --temperature 0.6  \
    --system_prompt_type amthinking \
    --max_workers 64

echo "ğŸ‰ All inference tasks completed successfully!"
```

**æ³¨æ„ï¼š** æˆ‘ä»¬ä½¿ç”¨é‡å¤é‡‡æ ·æ¥å‡å°‘è¯„ä¼°æ–¹å·®ï¼Œä½†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´æ‰èƒ½å®Œæˆï¼ˆæ ¹æ®è®¾å¤‡æƒ…å†µå¯èƒ½è¶…è¿‡8å°æ—¶ï¼‰ã€‚


æˆ‘ä»¬é‡‡ç”¨çš„è¯„æµ‹è¶…å‚å¦‚ä¸‹æ‰€ç¤ºï¼š

| é‡‡æ ·è¶…å‚       | å–å€¼                                       |
| -------------- | ------------------------------------------ |
| temperature    | 0.6                                        |
| top_k         | 40                                         |
| top_p         | 0.95                                       |
| max_model_len    | 131072                                     |
| system_prompt_type | amthinking |

##### æ­¥éª¤ 3ï¼šè¯„åˆ†

å®Œæˆæ¨ç†åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œè¯„åˆ†ï¼š

```bash
source set_env.sh

set -euo pipefail

# --- Configuration ---
output_dir="./output/PCL-Reasoner-v1"
n_samples=64 # Default sample size for aime24 and aime25

# Evaluation output directory
reval_dir="${output_dir}/eval_score"

# Create evaluation directory if it doesn't exist
mkdir -p "${reval_dir}"

# --- Evaluate Each Task ---
# Evaluate aime24
python ./llmeval/tasks/math_eval/eval.py \
    --input_path "${output_dir}/aime24_bz${n_samples}.jsonl" \
    --cache_path "${reval_dir}/aime24_bz${n_samples}.jsonl" \
    --task_name "math_opensource/aime24" \
    --max_workers 16 \
    > "${reval_dir}/aime24_bz${n_samples}_res_result.txt"

# Evaluate aime25
python ./llmeval/tasks/math_eval/eval.py \
    --input_path "${output_dir}/aime25_bz${n_samples}.jsonl" \
    --cache_path "${reval_dir}/aime25_bz${n_samples}.jsonl" \
    --task_name "math_opensource/aime25" \
    --max_workers 16 \
    > "${reval_dir}/aime25_bz${n_samples}_res_result.txt"

echo "ğŸ¯ Evaluation completed successfully!"
```


####  4.3 è¯„æµ‹ç»“æœ

æˆ‘ä»¬åœ¨AIME24/AIME25è¯„æµ‹ç»“æœè¯¦è§ä¸‹è¡¨æ•°æ®ã€‚ä¸ºç¡®ä¿è¯„ä¼°å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨Avg@32æŒ‡æ ‡ï¼ˆå¹³å‡32æ¬¡é‡‡æ ·ï¼‰è¿›è¡Œäº†è¯„æµ‹ï¼š

<!-- è¡¨æ ¼åŸºç¡€æ ·å¼ï¼ˆå¯é€‰æ·»åŠ ï¼‰ -->

<style>
  table { border-collapse: collapse; width: 100%; margin-left: auto;margin-right: auto;}
  th, td { border: 1px solid #ddd; padding: 8px; text-align: center; }
</style>

<!-- è¡¨æ ¼ä¸»ä½“ -->

<table>
  <tr>
    <th>æ¨¡å‹è§„æ ¼</th>
    <th>æ¨¡å‹</th>
    <th>AIME 24</th>
    <th>AIME 25</th>
  </tr>
  <!-- åˆå¹¶è¡Œè¡¨å¤´ >100B -->
  <tr>
    <th rowspan="6">&gt;100B</th>
  </tr>
  <!-- >100B ç»„æ•°æ®è¡Œ -->
  <tr>
    <td>DeepSeek-R1</td>
    <td><span style="color:grey">79.8</span></td>
    <td><span style="color:grey">70</span></td>
  </tr>
  <tr>
    <td>DeepSeek-R1-0528</td>
    <td><span style="color:red">91.4</span></td>
    <td><span style="color:red">87.5</span></td>
  </tr>
  <tr>
    <td>Qwen3-235B-A22B</td>
    <td><span style="color:grey">85.7</span></td>
    <td><span style="color:grey">81.5</span></td>
  </tr>
  <tr>
    <td>OpenAI-o3</td>
    <td><span style="color:red">91.6</span></td>
    <td><span style="color:red">88.9</span></td>
  </tr>
  <tr>
    <td>Gemini-2.5-Pro-0506</td>
    <td><span style="color:red">90.8</span></td>
    <td><span style="color:grey">83</span></td>
  </tr>
  <!-- åˆ†éš”è¡Œ -->
  <tr>
    <td colspan="4"></td>
  </tr>
  <!-- åˆå¹¶è¡Œè¡¨å¤´ 32B -->
  <tr>
    <th rowspan="7">32B</th>
  </tr>
  <!-- 32B ç»„æ•°æ®è¡Œ -->
  <tr>
    <td>Qwen3-32B</td>
    <td><span style="color:grey">81.4</span></td>
    <td><span style="color:grey">72.9</span></td>
  </tr>
  <tr>
    <td>QwQ-32B</td>
    <td><span style="color:grey">79.5</span></td> 
    <td><span style="color:grey">69.5</span></td>
  </tr>
  <tr>
    <td>DeepSeek-R1-Distill-Qwen-32B</td>
    <td><span style="color:grey">72.6</span></td>
    <td><span style="color:grey">49.6</span></td> 
  </tr>
  <tr>
    <td>Skywork-OR1-32B</td>
    <td><span style="color:grey">82.2</span></td>
    <td><span style="color:grey">73.3</span></td>
  </tr>
  <tr>
    <td>AM-Thinking-v1</td>
    <td><span style="color:grey">85.3</span></td>
    <td><span style="color:grey">74.4</span></td>
  </tr>
  <tr>
    <td>PCL-Reasoner-v1</td>
    <td><p style="font-weight: bold;">85.7</p></td> 
    <td><p style="font-weight: bold;">84.2</p></td> 
  </tr>
</table>

> *(æ³¨ï¼šæ¨¡å‹åœ¨AIME24/25è¯„æµ‹é›†ä¸Šçš„ç”Ÿæˆç»“æœæ–‡ä»¶å·²åŒæ­¥ä¸Šä¼ è‡³ `pcl_reasoner_v1/eval/eval_res`ç›®å½•ï¼Œä¾›å¼€å‘è€…ç”¨äºæ¨¡å‹éªŒè¯ä¸æ•ˆæœæ¯”å¯¹å‚è€ƒï¼‰*
 

å¦å¤–ï¼Œæˆ‘ä»¬ä¹Ÿé’ˆå¯¹è¯„æµ‹æ—¶ä¸åŒæ¨¡å‹å›ç­”é•¿åº¦ç»Ÿè®¡æ­£ç¡®ç‡ï¼Œå¯ä»¥çœ‹å‡ºAIME24/25è¯„æµ‹é›†å¯¹å›ç­”é•¿åº¦è¦æ±‚è¾ƒé«˜ï¼Œè€Œä¸”è¾ƒä¸ºç®€å•çš„AIME24ä¸Šï¼Œ64K tokensçš„å›ç­”é•¿åº¦å¯ä»¥æ»¡è¶³ï¼Œè€Œè¾ƒä¸ºéš¾çš„AIME25ä¸Šåˆ™éœ€è¦å›ç­”é•¿åº¦é•¿è¾¾128K tokensï¼š

<style>
  table { border-collapse: collapse; width: 100%; margin-left: auto;margin-right: auto;}
  th, td { border: 1px solid #ddd; padding: 8px; text-align: center; }
</style>

<table>
  <tr>
    <th>å›ç­”é•¿åº¦</th>
    <th>16k</th>
    <th>32k</th>
    <th>64k</th>
    <th>128k</th>
  </tr>
  <tr>
    <td>AIME24</td>
    <td>42.0</td>
    <td>77.9</td>
    <td>85.7</td>
    <td>85.7</td>
  </tr>
  <tr>
    <td>AIME25</td>
    <td>33.4</td>
    <td>75.6</td>
    <td>83.9</td>
    <td>84.2</td>
  </tr>
</table>
