# **PCL-Reasoner-V1.5 æ•°å­¦æ¨ç†æ¨¡å‹**

## æ¨¡å‹æ¦‚è§ˆ

PCL-Reasoner-V1.5 æ˜¯ä¸€ä¸ªä¸“ä¸ºæ•°å­¦æ¨ç†è®¾è®¡çš„ 32B å‚æ•°å¤§è¯­è¨€æ¨¡å‹ã€‚è¯¥æ¨¡å‹åŸºäº Qwen2.5-32B-Base æ„å»ºï¼Œé€šè¿‡ç›‘ç£å¾®è°ƒï¼ˆSupervised Fine-Tuning, SFTï¼‰ä¸å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learning, RLï¼‰è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬æ–¹æ³•çš„ä¸€é¡¹å…³é”®åˆ›æ–°åœ¨äºé‡‡ç”¨äº†ç¦»çº¿å¼ºåŒ–å­¦ä¹ ï¼ˆOffline RLï¼‰ï¼Œç›¸è¾ƒäºä¼ ç»Ÿçš„åœ¨çº¿å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾è‘—æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚
åœ¨å…¬å¼€æ•°æ®é›†ä¸Šï¼ŒPCL-Reasoner-V1.5 åœ¨ 32B è§„æ¨¡æ¨¡å‹ä¸­è¡¨ç°å“è¶Šï¼š

- åœ¨ AIME 2024 åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ° 91.3% çš„å¹³å‡å‡†ç¡®ç‡
- åœ¨ AIME 2025 åŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ° 91.0% çš„å¹³å‡å‡†ç¡®ç‡

æ‰€æœ‰å®éªŒå‡åœ¨åä¸ºæ˜‡è…¾ï¼ˆAscendï¼‰NPU ä¸Šå®Œæˆï¼Œä»…ä½¿ç”¨å…¬å¼€å¯ç”¨çš„æ•°æ®é›†ã€‚

ä¸ºä¿ƒè¿›æŠ€æœ¯å…±äº«ä¸åº”ç”¨ï¼Œæˆ‘ä»¬å·²å®Œæ•´å¼€æºäº†PCL-Reasoner-V1.5çš„æ¨¡å‹æƒé‡ã€æ•°æ®å¤„ç†åŠè®­ç»ƒä»£ç ã€‚è¯¥æ¨¡å‹ä¸ä»…æ˜¯å½“ä¸‹é¢†å…ˆçš„32Bæ•°å­¦æ¨ç†æ¨¡å‹ä¹‹ä¸€ï¼Œæ›´ä¸ºå¼€å‘è€…æä¾›äº†å®è´µçš„ä¸“ä¸šé¢†åŸŸç¦»çº¿å¼ºåŒ–å­¦ä¹ å®è·µç»éªŒä¸åè®­ç»ƒè§£å†³æ–¹æ¡ˆã€‚ç”¨æˆ·å¯å‚ç…§ä»¥ä¸‹æ•™ç¨‹è½»æ¾éƒ¨ç½²ä½“éªŒï¼Œæ·±å…¥æ¢ç´¢åè®­ç»ƒçš„å®è·µæ–¹æ³•ä¸å¥¥ç§˜ï¼


## å¼€å‘æŒ‡å¯¼

### 1. æ¨¡å‹æ–‡ä»¶

PCL-Reasoner-V1.5åŸºäºPCL-Reasoner-V1è¿›è¡Œå¾®è°ƒåè®­ç»ƒï¼Œè®­ç»ƒæµç¨‹åŸºäºMindSpeed-LLMæ¡†æ¶å®ç°ï¼Œä¸»è¦æ¶‰åŠçš„æ–‡ä»¶æœ‰ï¼š

```python

```



### 2.ç¯å¢ƒåŠæ•°æ®å‡†å¤‡

#### 2.1 å®‰è£…ç¯å¢ƒï¼š

| è½¯ä»¶      | ç‰ˆæœ¬       |
| --------- | ---------- |
| å›ºä»¶&é©±åŠ¨ | 24.1.rc3.5 |
| CANN      | 8.3.RC1    |
| Python    | 3.10       |


#### 2.2 æ•°æ®å¤„ç†

##### 2.2.1 æ•°æ®é›†ä¸‹è½½

è¦æƒ³è¿›ä¸€æ­¥æå‡PCL-Reasoner-V1çš„èƒ½åŠ›ï¼Œæˆ‘ä»¬è€ƒè™‘ä»Nvidiaå…¬å¼€çš„`Nemotron-Post-Training-Dataset-v1`ä¸­å¯»æ‰¾å…·å¤‡ä¸€å®šéš¾åº¦çš„é¢˜ç›®æ¥åšè¿›ä¸€æ­¥çš„è®­ç»ƒã€‚

| æ•°æ®é›†åç§°                    | æ•°æ®é›†é“¾æ¥                                                                                                                     |
| ----------------------------- | ------------------------------------------------------------------------------------------------------------------------------ |
| nvidia/Nemotron-Post-Training-Dataset-v1 | [https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v1](https://huggingface.co/datasets/nvidia/Nemotron-Post-Training-Dataset-v1) |

##### 2.2.2 æ•°æ®é¢„å¤„ç†

æ•°æ®é›†ä¸‹è½½åä¸ºparquetæ ¼å¼ï¼Œæˆ‘ä»¬é¦–å…ˆå°†æ•°æ®é›†è½¬æ¢ä¸ºjsonlæ ¼å¼ï¼Œæ–¹ä¾¿åç»­å¤„ç†ã€‚

```bash
# dir_path_to_parquet_files=Nemotron-Post-Training-Dataset-v1/data
# output_dir_path=Nemotron-Post-Training-Dataset-v1/orig2jsonl
cd PCL-Reasoner-V1.5/data_preprocess
python convert_parquet2jsonl.py $dir_path_to_parquet_files $output_dir_path  --workers 128
# å°†æ•°æ®é›†åˆå¹¶ä¸ºä¸€ä¸ªjsonlæ–‡ä»¶
cat $output_dir_path/*jsonl > Nemotron-Post-Training-Dataset-v1/all_samples.jsonl
```

ç»è¿‡ç»Ÿè®¡ï¼Œæˆ‘ä»¬å‘ç°åœ¨æ•°æ®é›†`Nemotron-Post-Training-Dataset-v1`ä¸­ï¼Œæ¯é“é¢˜è¢«é‡‡ç”¨äº†å¤šæ¬¡ï¼Œå¹¶ä¸”åªä¿ç•™äº†æ­£ç¡®çš„COTæ ·æœ¬ã€‚ å› æ­¤æˆ‘ä»¬å¯ä»¥æ®æ­¤è®¡ç®—æ¯é“é¢˜çš„å‡†ç¡®ç‡å’ŒCOTé•¿åº¦ã€‚æˆ‘ä»¬çš„æ•°æ®é¢„å¤„ç†åˆ†ä¸ºäº†3æ­¥ï¼š

1. æˆ‘ä»¬ç»Ÿè®¡äº†åŸå§‹æ•°æ®é›†ç›¸åŒé¢˜ç›®çš„COTä¸ªæ•°ï¼Œå‘ç°å¤§éƒ¨åˆ†éƒ½å¤„äº1-16æ¡ï¼Œè¿˜æœ‰æå°‘æ•°çš„å¤„äº17-32æ¡çš„åŒºé—´ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åˆ¤æ–­åŸå§‹æ•°æ®é›†æ˜¯å¯¹æ¯ä¸ªé¢˜ç›®æ¨ç†äº†16æ¬¡ï¼Œç„¶ååªä¿ç•™äº†æ­£ç¡®çš„COTæ ·æœ¬ã€‚å…¶ä¸­17-32æ¡çš„æ ·æœ¬å¯ä»¥ç†è§£ä¸ºæœ‰å°‘æ•°çš„é¢˜ç›®é‡å¤äº†ã€‚å› æ­¤æˆ‘ä»¬ç¬¬ä¸€æ­¥å°±æ˜¯å»æ‰COTæ¡æ•°ä¸º16å’Œ32çš„æ ·æœ¬ï¼Œå³å…¨å¯¹çš„æ ·æœ¬ï¼Œä¿ç•™æ¨ç†éƒ¨åˆ†æ­£ç¡®çš„æ ·æœ¬ï¼š
   ```bash
   cd PCL-Reasoner-V1.5/data_preprocess 
   python split_all_right_and_partial_right.py all_samples.jsonl --complete_output all_right_samples.jsonl --incomplete_output partial_right_samples.jsonl --processes 128 
   ```
   åŸå§‹æ•°æ®é›†æœ‰2044407æ¡COTæ•°æ®ï¼Œç»è¿‡å¤„ç†ï¼Œæˆ‘ä»¬å¾—åˆ°äº†1189392æ¡å®Œå…¨æ­£ç¡®çš„COTæ•°æ®ï¼ˆå…¨å¯¹çš„é¢˜ç›®è¿‡æ»¤æ‰ï¼‰ï¼Œå’Œ855015æ¡éƒ¨åˆ†æ­£ç¡®çš„COTæ•°æ®ã€‚

2. æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä»855015æ¡éƒ¨åˆ†æ­£ç¡®çš„COTæ•°æ®ä¸­ç­›é€‰å‡ºå¹³å‡COTé•¿åº¦å¤§äº32Kçš„COTæ•°æ®ï¼š
    ```bash
    cd PCL-Reasoner-V1.5/data_preprocess 
    python static_and_filter_cot.py partial_right_samples.jsonl partial_right_samples_cot_filter.jsonl path_to_tokenizer --processes 128
    ```
    ç»è¿‡å¤„ç†ï¼Œæˆ‘ä»¬åªå¾—åˆ°äº†34Kçš„é¢˜ç›®ï¼Œä¸”å¹³å‡COTé•¿åº¦å¤§äº32Kã€‚

3. æœ€åæˆ‘ä»¬å†ä»34Kçš„COTä¸­ï¼Œæ‰¾å‡ºå”¯ä¸€å‡ºç°çš„é¢˜ç›®:
   
   ```bash
   cd PCL-Reasoner-V1.5/data_preprocess 
   python extract_first_problem.py partial_right_samples_cot_filter.jsonl partial_right_problem.jsonl
   ```
   ç»è¿‡å¤„ç†ï¼Œæˆ‘ä»¬æœ€ç»ˆå¾—åˆ°äº†6Kçš„é¢˜ç›®ã€‚


##### 2.2.3 æ¨¡å‹é‡‡æ ·

æˆ‘ä»¬å¾—åˆ°è¿™6Kæ•°æ®é›†åï¼Œåˆ©ç”¨`PCL-Reasoner-V1`æ¨¡å‹è¿›è¡Œé‡‡æ ·ï¼Œæ¯é“é¢˜é‡‡æ ·8æ¬¡ï¼Œç”Ÿæˆæ¨ç†ç»“æœã€‚é‡‡æ ·çš„é…ç½®å¦‚ä¸‹ï¼š

xxx

ç»è¿‡é‡‡æ ·ï¼Œæˆ‘ä»¬å¾—åˆ°äº†48Kçš„COTæ•°æ®ã€‚

#### 2.2.4 é‡‡æ ·COTæ­£ç¡®æ€§è¯„ä¼°

æˆ‘ä»¬åœ¨ä»¥å¾€çš„è®­ç»ƒç»éªŒä¸­å‘ç°ï¼Œé‡‡ç”¨`math_verify`å¹¶ä¸èƒ½å¾ˆå¥½çš„å¯¹COTå›ç­”çš„æ­£ç¡®æ€§è¿›è¡Œè¯„ä¼°ã€‚å¯¹äºè¶Šæ˜¯å¤æ‚çš„æ•°å­¦é¢˜ï¼Œå…¶å®ƒç­”æ¡ˆå¦‚æœé‡‡ç”¨è§„åˆ™è¿›è¡ŒåŒ¹é…ï¼Œé‚£ä¹ˆå°±ä¼šæœ‰è¾ƒå¤§çš„è¯¯åˆ¤ã€‚å› æ­¤ï¼Œæˆ‘ä»¬é‡‡ç”¨`Qwen3-32B`æ¨¡å‹æ¥å¯¹COTçš„å›ç­”æ­£ç¡®æ€§è¿›è¡Œè¯„ä¼°ã€‚å…·ä½“æ€è·¯å¦‚ä¸‹ï¼š

1. ä¸º`Qwen3-32B`æ¨¡å‹ä¸“é—¨å†™ä¸€ä¸ªpromptï¼Œç”¨äºåˆ¤æ–­COTçš„æœ€åé‡Œé¢åŒ…å«çš„ç­”æ¡ˆæ˜¯å¦ä¸é¢˜ç›®æä¾›çš„ground truthä¸€è‡´ï¼›
2. éƒ¨ç½²`Qwen3-32B`æ¨¡å‹å¯¹48Ké¢˜ç›®è¿›è¡Œæ¨ç†ï¼›
3. æ ¹æ®`Qwen3-32B`æ¨¡å‹å¯¹COTçš„æœ€å300ä¸ªtokené‡Œé¢åŒ…å«çš„ç­”æ¡ˆå’Œé¢˜ç›®æä¾›çš„ground truthè¿›è¡ŒåŒ¹é…ä»ç„¶åˆ¤æ–­è¯¥æ¡COTæ˜¯å¦æ­£ç¡®ã€‚

promptæ¨¡æ¿å¦‚ä¸‹ï¼š

```bash
As a math scoring expert, given a standard answer, and a candidate answer, you need to compare whether the standard answer and the candidate answer are consistent. If they are consistent, return 1; if not, return 0. Remember the returned value should always be put in the \\boxed{}.\nHere are a few points to note:\n1. For the candidate answer, only consider the content inside \\boxed{}, ignoring any other text or error. If no \\boxed{} found, return 0 directly.\n2. If the standard answer and the candidate answer are different but mathematically equivalent, return 1.\n3. For answers involving decimals, if most digits are the same and only the last one or two digits differ, you may considerably return 1.\n4. For all other cases where the standard answer and the candidate answer do not match, return 0.\nHere is a task example:\n<Standard Answer Begin>\n{Standard answer}\n<Standard Answer End>\n<Candidate Answer Begin>\n{Candidate answer}\n<Candidate Answer End>\nPlease put your return value (0 or 1) as required above in the \\boxed{} without any explanation or description.\n<|im_end|>
```

æœ€ç»ˆï¼Œæˆ‘ä»¬å¾—åˆ°äº†22990æ¡æ­£æ ·æœ¬å’Œ25522æ¡è´Ÿæ ·æœ¬ã€‚

#### 2.3 æ¨¡å‹æƒé‡å‡†å¤‡

ç”¨æˆ·å¯ä»¥ä»`HuggingFace`å®˜æ–¹ä¸‹è½½`PCL-Reasoner-V1`æƒé‡

| æ¨¡å‹åç§°          | æƒé‡é“¾æ¥                                                                           |
| ----------------- | ---------------------------------------------------------------------------------- |
| PCL-Reasoner-V1 | [https://huggingface.co/PCL-Reasoner/V1](https://huggingface.co/PCL-Reasoner/V1) |

### 3 è®­ç»ƒæµç¨‹

æˆ‘ä»¬çš„è®­ç»ƒåŸºäºMindspeed-LLMæ¡†æ¶æ¶ï¼Œä¸»è¦åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š

#### 3.1 æ¨¡å‹æƒé‡è½¬æ¢

##### 3.1.1 ä¸‹è½½HuggingFaceæ¨¡å‹æƒé‡

ä¸‹è½½ HuggingFace ä¸Šçš„ Qwen25-32B-Base æ¨¡å‹æƒé‡åˆ°æœ¬åœ°ã€‚

```bash
# download  model
huggingface-cli download  Qwen/Qwen2.5-32B-Base  --local-dir ~/local/Qwen/Qwen2.5-32B-Base
```

##### 3.1.2 è½¬æ¢æ¨¡å‹æƒé‡æ ¼å¼

MindSpeed-LLMæ¡†æ¶åŸºäºMindSpeedï¼Œè¯»å–æƒé‡æ ¼å¼ä¸ºmcoreæ ¼å¼ï¼Œåœ¨è®­ç»ƒå‰ï¼Œéœ€è¦å°† Hugging Face æƒé‡è½¬æ¢æˆMcoreæ ¼å¼ã€‚è„šæœ¬å¯åŠ¨å‘½ä»¤å¯ä»¥ç”¨bashå¯åŠ¨ï¼Œå¯æ ¹æ®çœŸå®æƒ…å†µé…ç½®è„šæœ¬ï¼Œå¯åŠ¨å‘½ä»¤å’Œé…ç½®å‚æ•°å¦‚ä¸‹ï¼š
```bash
source /usr/local/Ascend/ascend-toolkit/set_env.sh

# è®¾ç½®éœ€è¦çš„æƒé‡è½¬æ¢å‚æ•°
python convert_ckpt.py \
       --use-mcore-models \
       --model-type GPT \
       --load-model-type hf \
       --save-model-type mg \
       --target-tensor-parallel-size 8 \
       --target-pipeline-parallel-size 4 \
       --add-qkv-bias \
       --load-dir ~/local/Qwen/Qwen2.5-32B \
       --save-dir ~/local/Qwen/mcore/qwen2.5_32b/ \
       --tokenizer-model ~/local/Qwen/Qwen2.5-32B/tokenizer.json \
       --model-type-hf llama2 \
       --params-dtype bf16
```

###### å‚æ•°ä»‹ç»

- `use-mcore-models`ï¼šå¯ç”¨ MCore æ¨¡å‹ï¼›
- `model-type`ï¼šæŒ‡å®šæ¨¡å‹ç±»å‹ï¼Œå¦‚ GPT;
- `load-model-type`ï¼šæŒ‡å®šåŠ è½½æ¨¡å‹çš„ç±»å‹ï¼Œå¦‚ hfï¼ˆHugging Faceï¼‰;
- `save-model-type`ï¼šæŒ‡å®šä¿å­˜æ¨¡å‹çš„ç±»å‹ï¼Œå¦‚ mg;
- `target-tensor-parallel-size`ï¼šè®¾ç½®ç›®æ ‡å¼ é‡å¹¶è¡Œå¤§å°ï¼›
- `target-pipeline-parallel-size`ï¼šè®¾ç½®ç›®æ ‡æµæ°´çº¿å¹¶è¡Œå¤§å°ï¼›
- `add-qkv-bias`ï¼šæ˜¯å¦è¿›è¡Œ QKV åç½®ï¼›
- `load-dir`ï¼šåŠ è½½ Hugging Face æƒé‡çš„è·¯å¾„ï¼›
- `save-dir`ï¼šä¿å­˜è½¬æ¢åæƒé‡çš„è·¯å¾„ï¼›
- `tokenizer-model`ï¼šåˆ†è¯å™¨æ¨¡å‹æ–‡ä»¶çš„è·¯å¾„ï¼›
- `model-type-hf`ï¼šæŒ‡å®š Hugging Face æ¨¡å‹ç±»å‹ï¼Œå¦‚ llama2;
- `params-dtype`ï¼šæŒ‡å®šå‚æ•°çš„æ•°æ®ç±»å‹ï¼Œå¦‚ bf16ã€‚



#### 3.2 æ•°æ®é›†è½¬æ¢

ç»è¿‡æ¨ç†ï¼Œæˆ‘ä»¬å¾—åˆ°äº†48Kçš„COTæ•°æ®ï¼Œæ•°æ®æ ¼å¼ä¸ºjsonlæ ¼å¼ï¼ŒåŒ…å«é—®é¢˜ã€æ¨ç†ç»“æœå’Œæ¨ç†ç»“æœå¯¹åº”çš„COTã€‚éœ€è¦å°†å…¶è½¬æ¢ä¸ºMindSpeed-LLMçš„å¯è¯»æ ¼å¼ï¼š


```bash
# è¯·æŒ‰ç…§æ‚¨çš„çœŸå®ç¯å¢ƒä¿®æ”¹ set_env.sh è·¯å¾„
source /usr/local/Ascend/ascend-toolkit/set_env.sh

python preprocess_data.py \
	--input /home/ma-user/work/datasets/open-web-math/open-web-math/data/ \
	--tokenizer-name-or-path /home/ma-user/work/models/Qwen/Qwen2.5-7B/ \
	--tokenizer-type PretrainedFromHF \
	--handler-name GeneralPretrainHandler \
	--cache-dir /home/ma-user/work/datasets/cache_dir \
	--output-prefix /home/ma-user/work/datasets/mindspeed/open-web-math \
	--json-keys text \
	--workers 16  \
	--n-subs 16 \
	--log-interval 1000
```

#### 3.3 è®­ç»ƒé…ç½®

#### 3.4 å¯åŠ¨è®­ç»ƒ

### 4. è¯„æµ‹æµç¨‹ï¼š

æˆ‘ä»¬ä½¿ç”¨ [LLMEval](https://gitee.com/jianzhnie/LLMEval) å¯¹æ¨¡å‹è¿›è¡Œè¯„æµ‹ï¼Œ LLMEval æ˜¯ç”±æˆ‘ä»¬å›¢é˜Ÿå¼€å‘çš„ä¸»è¦é’ˆå¯¹å¤§æ¨¡å‹æ¨ç†è¿›è¡Œè¯„æµ‹çš„å·¥å…·ï¼Œæ”¯æŒ vllm å’Œ sglang ä¸¤ç§æ¨ç†åç«¯ï¼Œ æ”¯æŒå¤šç§è¯„æµ‹æ•°æ®é›†ï¼Œ å·²ç»åœ¨ Ascend ç¯å¢ƒå¤ç°äº†å¤šä¸ªå¼€æºæ¨ç†æ¨¡å‹çš„æ•ˆæœã€‚è¯¦æƒ…è¯·å‚è€ƒ [LLMEval ä½¿ç”¨æ•™ç¨‹](https://gitee.com/jianzhnie/LLMEval)ã€‚

#### 4.1 è¯„ä¼°ç¯å¢ƒé…ç½®

#### 4.1.1 å®‰è£… vllm å’Œ vllm-ascend

è¯·å‚è€ƒ[vllm æ–‡æ¡£](https://vllm-ascend.readthedocs.io/en/latest/getting_started/installation.html) å’Œ [vllm-ascend æ–‡æ¡£](https://vllm-ascend.readthedocs.io/en/latest/getting_started/installation.html) å®‰è£… vllm å’Œ vllm-ascend ç¯å¢ƒã€‚

```bash
# Install vllm-project/vllm from pypi
pip install vllm==0.9.1

# Install vllm-project/vllm-ascend from pypi.
pip install vllm-ascend==0.9.1
```

#### 4.1.2 é…ç½® llmeval ç¯å¢ƒ

```bash
# Clone the LLMEval repository
git clone https://gitee.com/jianzhnie/LLMEval.git

# Navigate to the LLMEval directory
cd LLMEval
# Install LLMEval in editable mode
pip install -e .
```


#### 4.2 å¼€å§‹è¯„æµ‹

##### æ­¥éª¤ 1ï¼šå¯åŠ¨ vLLM æœåŠ¡å™¨

```bash
source set_env.sh

model_path="/path/to/pcl_reasoner_v1"
model_name="PCL-Reasoner-v1"

num_gpus=8
max_model_len=131072  # âœ… æ”¯æŒ 128k ä¸Šä¸‹æ–‡
gpu_memory_utilization=0.9  # âœ… æé«˜å†…å­˜åˆ©ç”¨ç‡

python -m vllm.entrypoints.openai.api_server \
    --model $model_path \
    --trust-remote-code \
    --served-model-name $model_name \
    --tensor-parallel-size $num_gpus \
    --gpu-memory-utilization $gpu_memory_utilization \
    --max-model-len $max_model_len  \
    --enforce-eager \
    --port 8090
```

æ ¹æ®å¯ç”¨è®¾å¤‡è°ƒæ•´ `tensor_parallel_size` å‚æ•°ã€‚


##### æ­¥éª¤ 2ï¼šæäº¤æ¨ç†ä»»åŠ¡

å¯åŠ¨ vLLM æœåŠ¡åï¼Œè¿è¡Œæ¨ç†è„šæœ¬ç”Ÿæˆå“åº”, å¹¶å°†ç»“æœä¿å­˜åˆ°æŒ‡å®šçš„è¾“å‡ºæ–‡ä»¶ä¸­ã€‚

```bash
source set_env.sh

set -euo pipefail

# --- Configuration ---
output_dir="./output/PCL-Reasoner-v1"
model_name="PCL-Reasoner-v1"

base_url="http://127.0.0.1:8090/v1"
n_samples=64  # Default sample size for aime24 and aime25

# Create output directory if it doesn't exist
mkdir -p "${output_dir}"

# --- Run Inference Tasks ---
# aime25 (repeated sample 64 times)
python ./llmeval/vllm/online_server.py \
    --input_file "./data/aime25.jsonl" \
    --input_key "prompt" \
    --output_file "${output_dir}/aime25_bz${n_samples}.jsonl" \
    --base_url "${base_url}" \
    --model_name "${model_name}" \
    --n_samples "${n_samples}" \
    --temperature 0.6  \
    --system_prompt_type amthinking \
    --max_workers 64

# aime24 (repeated sample 64 times)
python ./llmeval/vllm/online_server.py \
    --input_file "./data/aime24.jsonl" \
    --input_key "prompt" \
    --output_file "${output_dir}/aime24_bz${n_samples}.jsonl" \
    --base_url "${base_url}" \
    --model_name "${model_name}" \
    --n_samples "${n_samples}" \
    --temperature 0.6  \
    --system_prompt_type amthinking \
    --max_workers 64

echo "ğŸ‰ All inference tasks completed successfully!"
```

**æ³¨æ„ï¼š** æˆ‘ä»¬ä½¿ç”¨é‡å¤é‡‡æ ·æ¥å‡å°‘è¯„ä¼°æ–¹å·®ï¼Œä½†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´æ‰èƒ½å®Œæˆï¼ˆæ ¹æ®è®¾å¤‡æƒ…å†µå¯èƒ½è¶…è¿‡8å°æ—¶ï¼‰ã€‚


æˆ‘ä»¬é‡‡ç”¨çš„è¯„æµ‹è¶…å‚å¦‚ä¸‹æ‰€ç¤ºï¼š

| é‡‡æ ·è¶…å‚       | å–å€¼                                       |
| -------------- | ------------------------------------------ |
| temperature    | 0.6                                        |
| top_k         | 40                                         |
| top_p         | 0.95                                       |
| max_model_len    | 131072                                     |
| system_prompt_type | amthinking |

##### æ­¥éª¤ 3ï¼šè¯„åˆ†

å®Œæˆæ¨ç†åï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿›è¡Œè¯„åˆ†ï¼š

```bash
source set_env.sh

set -euo pipefail

# --- Configuration ---
output_dir="./output/PCL-Reasoner-v1"
n_samples=64 # Default sample size for aime24 and aime25

# Evaluation output directory
reval_dir="${output_dir}/eval_score"

# Create evaluation directory if it doesn't exist
mkdir -p "${reval_dir}"

# --- Evaluate Each Task ---
# Evaluate aime24
python ./llmeval/tasks/math_eval/eval.py \
    --input_path "${output_dir}/aime24_bz${n_samples}.jsonl" \
    --cache_path "${reval_dir}/aime24_bz${n_samples}.jsonl" \
    --task_name "math_opensource/aime24" \
    --max_workers 16 \
    > "${reval_dir}/aime24_bz${n_samples}_res_result.txt"

# Evaluate aime25
python ./llmeval/tasks/math_eval/eval.py \
    --input_path "${output_dir}/aime25_bz${n_samples}.jsonl" \
    --cache_path "${reval_dir}/aime25_bz${n_samples}.jsonl" \
    --task_name "math_opensource/aime25" \
    --max_workers 16 \
    > "${reval_dir}/aime25_bz${n_samples}_res_result.txt"

echo "ğŸ¯ Evaluation completed successfully!"
```


####  4.3 è¯„æµ‹ç»“æœ

æˆ‘ä»¬åœ¨AIME24/AIME25è¯„æµ‹ç»“æœè¯¦è§ä¸‹è¡¨æ•°æ®ã€‚ä¸ºç¡®ä¿è¯„ä¼°å‡†ç¡®æ€§ï¼Œæˆ‘ä»¬é‡‡ç”¨Avg@32æŒ‡æ ‡ï¼ˆå¹³å‡32æ¬¡é‡‡æ ·ï¼‰è¿›è¡Œäº†è¯„æµ‹ï¼š

<!-- è¡¨æ ¼åŸºç¡€æ ·å¼ï¼ˆå¯é€‰æ·»åŠ ï¼‰ -->

<style>
  table { border-collapse: collapse; width: 100%; margin-left: auto;margin-right: auto;}
  th, td { border: 1px solid #ddd; padding: 8px; text-align: center; }
</style>

<!-- è¡¨æ ¼ä¸»ä½“ -->

<table>
  <tr>
    <th>æ¨¡å‹è§„æ ¼</th>
    <th>æ¨¡å‹</th>
    <th>AIME 24</th>
    <th>AIME 25</th>
  </tr>
  <!-- åˆå¹¶è¡Œè¡¨å¤´ >100B -->
  <tr>
    <th rowspan="6">&gt;100B</th>
  </tr>
  <!-- >100B ç»„æ•°æ®è¡Œ -->
  <tr>
    <td>DeepSeek-R1</td>
    <td><span style="color:grey">79.8</span></td>
    <td><span style="color:grey">70</span></td>
  </tr>
  <tr>
    <td>DeepSeek-R1-0528</td>
    <td><span style="color:red">91.4</span></td>
    <td><span style="color:red">87.5</span></td>
  </tr>
  <tr>
    <td>Qwen3-235B-A22B</td>
    <td><span style="color:grey">85.7</span></td>
    <td><span style="color:grey">81.5</span></td>
  </tr>
  <tr>
    <td>OpenAI-o3</td>
    <td><span style="color:red">91.6</span></td>
    <td><span style="color:red">88.9</span></td>
  </tr>
  <tr>
    <td>Gemini-2.5-Pro-0506</td>
    <td><span style="color:red">90.8</span></td>
    <td><span style="color:grey">83</span></td>
  </tr>
  <!-- åˆ†éš”è¡Œ -->
  <tr>
    <td colspan="4"></td>
  </tr>
  <!-- åˆå¹¶è¡Œè¡¨å¤´ 32B -->
  <tr>
    <th rowspan="7">32B</th>
  </tr>
  <!-- 32B ç»„æ•°æ®è¡Œ -->
  <tr>
    <td>Qwen3-32B</td>
    <td><span style="color:grey">81.4</span></td>
    <td><span style="color:grey">72.9</span></td>
  </tr>
  <tr>
    <td>QwQ-32B</td>
    <td><span style="color:grey">79.5</span></td> 
    <td><span style="color:grey">69.5</span></td>
  </tr>
  <tr>
    <td>DeepSeek-R1-Distill-Qwen-32B</td>
    <td><span style="color:grey">72.6</span></td>
    <td><span style="color:grey">49.6</span></td> 
  </tr>
  <tr>
    <td>Skywork-OR1-32B</td>
    <td><span style="color:grey">82.2</span></td>
    <td><span style="color:grey">73.3</span></td>
  </tr>
  <tr>
    <td>AM-Thinking-v1</td>
    <td><span style="color:grey">85.3</span></td>
    <td><span style="color:grey">74.4</span></td>
  </tr>
  <tr>
    <td>PCL-Reasoner-v1</td>
    <td><p style="font-weight: bold;">85.7</p></td> 
    <td><p style="font-weight: bold;">84.2</p></td> 
  </tr>
</table>

> *(æ³¨ï¼šæ¨¡å‹åœ¨AIME24/25è¯„æµ‹é›†ä¸Šçš„ç”Ÿæˆç»“æœæ–‡ä»¶å·²åŒæ­¥ä¸Šä¼ è‡³ `PCL-Reasoner-V1.5/eval_result`ç›®å½•ï¼Œä¾›å¼€å‘è€…ç”¨äºæ¨¡å‹éªŒè¯ä¸æ•ˆæœæ¯”å¯¹å‚è€ƒï¼‰*

## Ciation

```bibtex
@article{PCL-Reasoner-v1.5,
  title={PCL-Reasoner-v1.5: A Math Problem Solver with Chain of Thought Reasoning},
  author={Yao Lu, Deng Dong Fan, Jianzheng Nie, et al.},
  journal={arXiv preprint arXiv:2405.14524},
  year={2024}
}
```